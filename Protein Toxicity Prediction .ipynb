{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf80afe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e277f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c0faf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSA1</th>\n",
       "      <th>LSA2</th>\n",
       "      <th>LSA3</th>\n",
       "      <th>LSA4</th>\n",
       "      <th>LSA5</th>\n",
       "      <th>LSA6</th>\n",
       "      <th>LSA7</th>\n",
       "      <th>LSA8</th>\n",
       "      <th>LSA9</th>\n",
       "      <th>LSA10</th>\n",
       "      <th>...</th>\n",
       "      <th>CKSAAGP92</th>\n",
       "      <th>CKSAAGP93</th>\n",
       "      <th>CKSAAGP94</th>\n",
       "      <th>CKSAAGP95</th>\n",
       "      <th>CKSAAGP96</th>\n",
       "      <th>CKSAAGP97</th>\n",
       "      <th>CKSAAGP98</th>\n",
       "      <th>CKSAAGP99</th>\n",
       "      <th>CKSAAGP100</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885421</td>\n",
       "      <td>-0.090143</td>\n",
       "      <td>0.052041</td>\n",
       "      <td>-0.215175</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>-0.016267</td>\n",
       "      <td>0.033283</td>\n",
       "      <td>0.066139</td>\n",
       "      <td>-0.031209</td>\n",
       "      <td>0.123995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859651</td>\n",
       "      <td>0.089647</td>\n",
       "      <td>-0.370006</td>\n",
       "      <td>0.086477</td>\n",
       "      <td>-0.097067</td>\n",
       "      <td>0.014087</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>-0.050251</td>\n",
       "      <td>0.063698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.144397</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.090517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.849490</td>\n",
       "      <td>0.127310</td>\n",
       "      <td>-0.350845</td>\n",
       "      <td>-0.114950</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>-0.074546</td>\n",
       "      <td>-0.106896</td>\n",
       "      <td>-0.045566</td>\n",
       "      <td>0.026401</td>\n",
       "      <td>-0.027316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.146283</td>\n",
       "      <td>0.026379</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.062350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.898339</td>\n",
       "      <td>-0.005396</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.086425</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.069580</td>\n",
       "      <td>-0.069316</td>\n",
       "      <td>-0.028810</td>\n",
       "      <td>-0.011817</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.031621</td>\n",
       "      <td>0.098814</td>\n",
       "      <td>0.031621</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.051383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875390</td>\n",
       "      <td>-0.128121</td>\n",
       "      <td>0.031999</td>\n",
       "      <td>-0.203435</td>\n",
       "      <td>0.271215</td>\n",
       "      <td>-0.056642</td>\n",
       "      <td>0.115523</td>\n",
       "      <td>0.027076</td>\n",
       "      <td>-0.078173</td>\n",
       "      <td>-0.034989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.044619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>0.786431</td>\n",
       "      <td>-0.034371</td>\n",
       "      <td>-0.279516</td>\n",
       "      <td>0.042491</td>\n",
       "      <td>-0.036919</td>\n",
       "      <td>0.148707</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>-0.068920</td>\n",
       "      <td>0.124956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.119318</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34299</th>\n",
       "      <td>0.851649</td>\n",
       "      <td>-0.140014</td>\n",
       "      <td>-0.196052</td>\n",
       "      <td>-0.008534</td>\n",
       "      <td>0.134372</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>-0.115211</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.112727</td>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>0.029091</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34300</th>\n",
       "      <td>0.859095</td>\n",
       "      <td>-0.185632</td>\n",
       "      <td>-0.012825</td>\n",
       "      <td>-0.213118</td>\n",
       "      <td>-0.034574</td>\n",
       "      <td>0.074301</td>\n",
       "      <td>0.065004</td>\n",
       "      <td>0.163299</td>\n",
       "      <td>-0.062225</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34301</th>\n",
       "      <td>0.926410</td>\n",
       "      <td>-0.168513</td>\n",
       "      <td>-0.076104</td>\n",
       "      <td>0.016629</td>\n",
       "      <td>0.075252</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>-0.037262</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>-0.115388</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>0.031773</td>\n",
       "      <td>0.102007</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.031773</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.095318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34302</th>\n",
       "      <td>0.812622</td>\n",
       "      <td>-0.167440</td>\n",
       "      <td>0.224042</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>-0.095829</td>\n",
       "      <td>0.060580</td>\n",
       "      <td>0.131802</td>\n",
       "      <td>-0.019431</td>\n",
       "      <td>-0.049399</td>\n",
       "      <td>-0.132094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.022321</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34303 rows Ã— 803 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LSA1      LSA2      LSA3      LSA4      LSA5      LSA6      LSA7  \\\n",
       "0      0.885421 -0.090143  0.052041 -0.215175  0.086147 -0.016267  0.033283   \n",
       "1      0.859651  0.089647 -0.370006  0.086477 -0.097067  0.014087  0.100377   \n",
       "2      0.849490  0.127310 -0.350845 -0.114950  0.013077 -0.074546 -0.106896   \n",
       "3      0.898339 -0.005396 -0.007376 -0.086425  0.117117  0.069580 -0.069316   \n",
       "4      0.875390 -0.128121  0.031999 -0.203435  0.271215 -0.056642  0.115523   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "34298  0.786431 -0.034371 -0.279516  0.042491 -0.036919  0.148707  0.033410   \n",
       "34299  0.851649 -0.140014 -0.196052 -0.008534  0.134372  0.012691  0.029572   \n",
       "34300  0.859095 -0.185632 -0.012825 -0.213118 -0.034574  0.074301  0.065004   \n",
       "34301  0.926410 -0.168513 -0.076104  0.016629  0.075252  0.046100 -0.037262   \n",
       "34302  0.812622 -0.167440  0.224042  0.033708 -0.095829  0.060580  0.131802   \n",
       "\n",
       "           LSA8      LSA9     LSA10  ...  CKSAAGP92  CKSAAGP93  CKSAAGP94  \\\n",
       "0      0.066139 -0.031209  0.123995  ...   0.007874   0.027559   0.007874   \n",
       "1      0.061634 -0.050251  0.063698  ...   0.006466   0.004310   0.002155   \n",
       "2     -0.045566  0.026401 -0.027316  ...   0.000000   0.004796   0.009592   \n",
       "3     -0.028810 -0.011817  0.025901  ...   0.015810   0.011858   0.003953   \n",
       "4      0.027076 -0.078173 -0.034989  ...   0.007874   0.028871   0.013123   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "34298  0.055656 -0.068920  0.124956  ...   0.005682   0.005682   0.000000   \n",
       "34299  0.010968 -0.115211  0.050656  ...   0.003636   0.021818   0.018182   \n",
       "34300  0.163299 -0.062225  0.015260  ...   0.002976   0.011905   0.020833   \n",
       "34301  0.058495 -0.115388  0.033430  ...   0.011706   0.021739   0.016722   \n",
       "34302 -0.019431 -0.049399 -0.132094  ...   0.022321   0.031250   0.013393   \n",
       "\n",
       "       CKSAAGP95  CKSAAGP96  CKSAAGP97  CKSAAGP98  CKSAAGP99  CKSAAGP100  \\\n",
       "0       0.035433   0.094488   0.007874   0.031496   0.023622    0.031496   \n",
       "1       0.012931   0.144397   0.036638   0.021552   0.021552    0.090517   \n",
       "2       0.016787   0.146283   0.026379   0.011990   0.016787    0.062350   \n",
       "3       0.031621   0.098814   0.031621   0.023715   0.043478    0.051383   \n",
       "4       0.013123   0.110236   0.007874   0.026247   0.013123    0.044619   \n",
       "...          ...        ...        ...        ...        ...         ...   \n",
       "34298   0.039773   0.119318   0.022727   0.068182   0.022727    0.130682   \n",
       "34299   0.036364   0.112727   0.043636   0.025455   0.029091    0.065455   \n",
       "34300   0.023810   0.101190   0.038690   0.044643   0.017857    0.169643   \n",
       "34301   0.031773   0.102007   0.013378   0.031773   0.046823    0.095318   \n",
       "34302   0.022321   0.098214   0.013393   0.035714   0.040179    0.040179   \n",
       "\n",
       "       target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "34298       1  \n",
       "34299       1  \n",
       "34300       1  \n",
       "34301       1  \n",
       "34302       1  \n",
       "\n",
       "[34303 rows x 803 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Merge Copy.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2926452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22222\n",
       "1    12081\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc772c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the variable we are predicting\n",
    "target = 'target'\n",
    "Y = df[target]\n",
    "\n",
    "X= df.drop(target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c2bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split (X,Y,test_size=0.3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399a38a",
   "metadata": {},
   "source": [
    "# **Adasyn balancing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1109d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before ADASYN: Counter({0: 15620, 1: 8392})\n",
      "The number of classes after ADASYN: Counter({0: 15620, 1: 15163})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "# Instantiate the ADASYN resampler\n",
    "adasyn = ADASYN()\n",
    "\n",
    "# Resample the training data\n",
    "X_train_balanced, Y_train_balanced = adasyn.fit_resample(X_train, Y_train)\n",
    "\n",
    "# Print the number of classes before and after resampling\n",
    "print(\"The number of classes before ADASYN: {}\".format(Counter(Y_train)))\n",
    "print(\"The number of classes after ADASYN: {}\".format(Counter(Y_train_balanced)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1b5d9",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a21fc73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Classifier  Accuracy       mcc  \\\n",
      "0   RandomForestClassifier(max_depth=5, n_estimato...  0.772147  0.557192   \n",
      "1   XGBClassifier(base_score=None, booster=None, c...  0.998408  0.996819   \n",
      "2   LGBMClassifier(max_depth=5, num_leaves=63, ran...  0.993958  0.987964   \n",
      "3   GradientBoostingClassifier(learning_rate=0.5, ...  0.996654  0.993323   \n",
      "4   AdaBoostClassifier(learning_rate=0.1, n_estima...  0.869863  0.741809   \n",
      "5   <catboost.core.CatBoostClassifier object at 0x...  0.986908  0.973896   \n",
      "6   ExtraTreesClassifier(max_depth=5, n_estimators...  0.677452  0.370163   \n",
      "7            KNeighborsClassifier(weights='distance')  0.743885  0.570774   \n",
      "8                 DecisionTreeClassifier(max_depth=7)  0.889387  0.780540   \n",
      "9                                               SVC()  0.732677  0.467918   \n",
      "10                                       GaussianNB()  0.688724  0.384722   \n",
      "\n",
      "       Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0   0.542658   0.848755  0.653960  0.738732     0.886876     0.653960  \n",
      "1   0.996816   0.997040  0.999736  0.998386     0.997119     0.999736  \n",
      "2   0.987915   0.988901  0.998945  0.993898     0.989117     0.998945  \n",
      "3   0.993307   0.993770  0.999472  0.996613     0.993918     0.999472  \n",
      "4   0.739943   0.843187  0.903911  0.872493     0.836812     0.903911  \n",
      "5   0.973816   0.980469  0.993207  0.986797     0.980794     0.993207  \n",
      "6   0.351780   0.751731  0.515399  0.611526     0.834763     0.515399  \n",
      "7   0.491523   0.657930  0.999934  0.793656     0.495327     0.999934  \n",
      "8   0.778936   0.864025  0.920266  0.891259     0.859411     0.920266  \n",
      "9   0.464243   0.761818  0.665304  0.710297     0.798079     0.665304  \n",
      "10  0.375275   0.736784  0.572644  0.644426     0.801408     0.572644  \n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "#total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 5),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 5, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate=0.1, max_depth=5, num_leaves=63, random_state=50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50),\n",
    "          CatBoostClassifier(depth= 5, iterations = 35, learning_rate = 0.35),\n",
    "          ExtraTreesClassifier(n_estimators=200, max_depth=5, random_state=42),\n",
    "          KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "          DecisionTreeClassifier(max_depth=7),\n",
    "          SVC(C=1.0, kernel='rbf'),\n",
    "          GaussianNB()]\n",
    "\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  \n",
    "  pred = cross_val_predict(model, X_train_balanced, Y_train_balanced, cv=cv, n_jobs=-1)\n",
    "\n",
    "  \n",
    "  Accuracy = accuracy_score(Y_train_balanced, pred)\n",
    "  mcc = matthews_corrcoef(Y_train_balanced, pred)\n",
    "  cm1 = confusion_matrix(Y_train_balanced, pred)\n",
    "  kappa = cohen_kappa_score(Y_train_balanced, pred)\n",
    "  f1 = f1_score(Y_train_balanced, pred)\n",
    "  precision_score = precision_score(Y_train_balanced, pred)\n",
    "  recall_score = recall_score(Y_train_balanced, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    " \n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)\n",
    "total_Metics.to_csv(\"Merge ML_train_adasyn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45299763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier(max_depth=5, n_estimato...</td>\n",
       "      <td>0.772147</td>\n",
       "      <td>0.557192</td>\n",
       "      <td>0.542658</td>\n",
       "      <td>0.848755</td>\n",
       "      <td>0.653960</td>\n",
       "      <td>0.738732</td>\n",
       "      <td>0.886876</td>\n",
       "      <td>0.653960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.996819</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.997040</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.998386</td>\n",
       "      <td>0.997119</td>\n",
       "      <td>0.999736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LGBMClassifier(max_depth=5, num_leaves=63, ran...</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.987964</td>\n",
       "      <td>0.987915</td>\n",
       "      <td>0.988901</td>\n",
       "      <td>0.998945</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.989117</td>\n",
       "      <td>0.998945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier(learning_rate=0.5, ...</td>\n",
       "      <td>0.996654</td>\n",
       "      <td>0.993323</td>\n",
       "      <td>0.993307</td>\n",
       "      <td>0.993770</td>\n",
       "      <td>0.999472</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>0.993918</td>\n",
       "      <td>0.999472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.1, n_estima...</td>\n",
       "      <td>0.869863</td>\n",
       "      <td>0.741809</td>\n",
       "      <td>0.739943</td>\n",
       "      <td>0.843187</td>\n",
       "      <td>0.903911</td>\n",
       "      <td>0.872493</td>\n",
       "      <td>0.836812</td>\n",
       "      <td>0.903911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.986908</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.973816</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.993207</td>\n",
       "      <td>0.986797</td>\n",
       "      <td>0.980794</td>\n",
       "      <td>0.993207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier(max_depth=5, n_estimators...</td>\n",
       "      <td>0.677452</td>\n",
       "      <td>0.370163</td>\n",
       "      <td>0.351780</td>\n",
       "      <td>0.751731</td>\n",
       "      <td>0.515399</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.834763</td>\n",
       "      <td>0.515399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier(weights='distance')</td>\n",
       "      <td>0.743885</td>\n",
       "      <td>0.570774</td>\n",
       "      <td>0.491523</td>\n",
       "      <td>0.657930</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.793656</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.999934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=7)</td>\n",
       "      <td>0.889387</td>\n",
       "      <td>0.780540</td>\n",
       "      <td>0.778936</td>\n",
       "      <td>0.864025</td>\n",
       "      <td>0.920266</td>\n",
       "      <td>0.891259</td>\n",
       "      <td>0.859411</td>\n",
       "      <td>0.920266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.732677</td>\n",
       "      <td>0.467918</td>\n",
       "      <td>0.464243</td>\n",
       "      <td>0.761818</td>\n",
       "      <td>0.665304</td>\n",
       "      <td>0.710297</td>\n",
       "      <td>0.798079</td>\n",
       "      <td>0.665304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.688724</td>\n",
       "      <td>0.384722</td>\n",
       "      <td>0.375275</td>\n",
       "      <td>0.736784</td>\n",
       "      <td>0.572644</td>\n",
       "      <td>0.644426</td>\n",
       "      <td>0.801408</td>\n",
       "      <td>0.572644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                         Classifier  Accuracy  \\\n",
       "0            0  RandomForestClassifier(max_depth=5, n_estimato...  0.772147   \n",
       "1            1  XGBClassifier(base_score=None, booster=None, c...  0.998408   \n",
       "2            2  LGBMClassifier(max_depth=5, num_leaves=63, ran...  0.993958   \n",
       "3            3  GradientBoostingClassifier(learning_rate=0.5, ...  0.996654   \n",
       "4            4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.869863   \n",
       "5            5  <catboost.core.CatBoostClassifier object at 0x...  0.986908   \n",
       "6            6  ExtraTreesClassifier(max_depth=5, n_estimators...  0.677452   \n",
       "7            7           KNeighborsClassifier(weights='distance')  0.743885   \n",
       "8            8                DecisionTreeClassifier(max_depth=7)  0.889387   \n",
       "9            9                                              SVC()  0.732677   \n",
       "10          10                                       GaussianNB()  0.688724   \n",
       "\n",
       "         mcc     Kappa  precision    recall        f1  sensitivity  \\\n",
       "0   0.557192  0.542658   0.848755  0.653960  0.738732     0.886876   \n",
       "1   0.996819  0.996816   0.997040  0.999736  0.998386     0.997119   \n",
       "2   0.987964  0.987915   0.988901  0.998945  0.993898     0.989117   \n",
       "3   0.993323  0.993307   0.993770  0.999472  0.996613     0.993918   \n",
       "4   0.741809  0.739943   0.843187  0.903911  0.872493     0.836812   \n",
       "5   0.973896  0.973816   0.980469  0.993207  0.986797     0.980794   \n",
       "6   0.370163  0.351780   0.751731  0.515399  0.611526     0.834763   \n",
       "7   0.570774  0.491523   0.657930  0.999934  0.793656     0.495327   \n",
       "8   0.780540  0.778936   0.864025  0.920266  0.891259     0.859411   \n",
       "9   0.467918  0.464243   0.761818  0.665304  0.710297     0.798079   \n",
       "10  0.384722  0.375275   0.736784  0.572644  0.644426     0.801408   \n",
       "\n",
       "    specificity  \n",
       "0      0.653960  \n",
       "1      0.999736  \n",
       "2      0.998945  \n",
       "3      0.999472  \n",
       "4      0.903911  \n",
       "5      0.993207  \n",
       "6      0.515399  \n",
       "7      0.999934  \n",
       "8      0.920266  \n",
       "9      0.665304  \n",
       "10     0.572644  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Result = pd.read_csv('Merge ML_train_adasyn.csv')\n",
    "Train_Result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a785c",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32364ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 15163, number of negative: 15620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 204510\n",
      "[LightGBM] [Info] Number of data points in the train set: 30783, number of used features: 802\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492577 -> initscore=-0.029694\n",
      "[LightGBM] [Info] Start training from score -0.029694\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0:\tlearn: 0.5084869\ttotal: 346ms\tremaining: 11.7s\n",
      "1:\tlearn: 0.4258981\ttotal: 472ms\tremaining: 7.78s\n",
      "2:\tlearn: 0.3531039\ttotal: 591ms\tremaining: 6.3s\n",
      "3:\tlearn: 0.3167592\ttotal: 714ms\tremaining: 5.54s\n",
      "4:\tlearn: 0.2938406\ttotal: 839ms\tremaining: 5.03s\n",
      "5:\tlearn: 0.2813443\ttotal: 946ms\tremaining: 4.57s\n",
      "6:\tlearn: 0.2396902\ttotal: 1.07s\tremaining: 4.27s\n",
      "7:\tlearn: 0.2296347\ttotal: 1.17s\tremaining: 3.96s\n",
      "8:\tlearn: 0.2125403\ttotal: 1.3s\tremaining: 3.75s\n",
      "9:\tlearn: 0.2010955\ttotal: 1.41s\tremaining: 3.51s\n",
      "10:\tlearn: 0.1887985\ttotal: 1.51s\tremaining: 3.3s\n",
      "11:\tlearn: 0.1803723\ttotal: 1.62s\tremaining: 3.11s\n",
      "12:\tlearn: 0.1749169\ttotal: 1.72s\tremaining: 2.92s\n",
      "13:\tlearn: 0.1695930\ttotal: 1.83s\tremaining: 2.74s\n",
      "14:\tlearn: 0.1625333\ttotal: 1.94s\tremaining: 2.58s\n",
      "15:\tlearn: 0.1562676\ttotal: 2.04s\tremaining: 2.43s\n",
      "16:\tlearn: 0.1513737\ttotal: 2.15s\tremaining: 2.27s\n",
      "17:\tlearn: 0.1475008\ttotal: 2.27s\tremaining: 2.14s\n",
      "18:\tlearn: 0.1435495\ttotal: 2.37s\tremaining: 1.99s\n",
      "19:\tlearn: 0.1312269\ttotal: 2.5s\tremaining: 1.88s\n",
      "20:\tlearn: 0.1269738\ttotal: 2.61s\tremaining: 1.74s\n",
      "21:\tlearn: 0.1226520\ttotal: 2.71s\tremaining: 1.6s\n",
      "22:\tlearn: 0.1132616\ttotal: 2.84s\tremaining: 1.48s\n",
      "23:\tlearn: 0.1087133\ttotal: 2.96s\tremaining: 1.35s\n",
      "24:\tlearn: 0.1037491\ttotal: 3.06s\tremaining: 1.23s\n",
      "25:\tlearn: 0.0957131\ttotal: 3.2s\tremaining: 1.11s\n",
      "26:\tlearn: 0.0922054\ttotal: 3.32s\tremaining: 983ms\n",
      "27:\tlearn: 0.0864314\ttotal: 3.44s\tremaining: 861ms\n",
      "28:\tlearn: 0.0832597\ttotal: 3.56s\tremaining: 736ms\n",
      "29:\tlearn: 0.0801117\ttotal: 3.67s\tremaining: 611ms\n",
      "30:\tlearn: 0.0772509\ttotal: 3.8s\tremaining: 490ms\n",
      "31:\tlearn: 0.0749860\ttotal: 3.92s\tremaining: 367ms\n",
      "32:\tlearn: 0.0728578\ttotal: 4.02s\tremaining: 244ms\n",
      "33:\tlearn: 0.0699735\ttotal: 4.13s\tremaining: 122ms\n",
      "34:\tlearn: 0.0675713\ttotal: 4.25s\tremaining: 0us\n",
      "                                           Classifier  Accuracy       mcc  \\\n",
      "0   (DecisionTreeClassifier(max_depth=5, max_featu...  0.821106  0.604587   \n",
      "1   XGBClassifier(base_score=None, booster=None, c...  0.997571  0.994728   \n",
      "2   LGBMClassifier(max_depth=5, num_leaves=63, ran...  0.992809  0.984500   \n",
      "3   ([DecisionTreeRegressor(criterion='friedman_ms...  0.996113  0.991584   \n",
      "4   (DecisionTreeClassifier(max_depth=1, random_st...  0.858906  0.713902   \n",
      "5   <catboost.core.CatBoostClassifier object at 0x...  0.982315  0.962015   \n",
      "6   (ExtraTreeClassifier(max_depth=5, random_state...  0.775435  0.506377   \n",
      "7            KNeighborsClassifier(weights='distance')  0.690895  0.522171   \n",
      "8                 DecisionTreeClassifier(max_depth=7)  0.880381  0.757799   \n",
      "9                                               SVC()  0.802449  0.588533   \n",
      "10                                       GaussianNB()  0.784472  0.542569   \n",
      "\n",
      "       Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0   0.602950   0.775986  0.704256  0.738383     0.886398     0.704256  \n",
      "1   0.994723   0.994600  0.998645  0.996618     0.996971     0.998645  \n",
      "2   0.984422   0.982129  0.998102  0.990051     0.989852     0.998102  \n",
      "3   0.991564   0.990589  0.998645  0.994600     0.994699     0.998645  \n",
      "4   0.706064   0.753112  0.902142  0.820918     0.834747     0.902142  \n",
      "5   0.961786   0.962299  0.989428  0.975675     0.978340     0.989428  \n",
      "6   0.505928   0.697308  0.660070  0.678179     0.839897     0.660070  \n",
      "7   0.433820   0.537265  0.992681  0.697192     0.522266     0.992681  \n",
      "8   0.750273   0.780466  0.927081  0.847479     0.854287     0.927081  \n",
      "9   0.584569   0.694549  0.801301  0.744116     0.803090     0.801301  \n",
      "10  0.541112   0.681919  0.747357  0.713140     0.805211     0.747357  \n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "#total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "# cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 5),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 5, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate=0.1, max_depth=5, num_leaves=63, random_state=50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50),\n",
    "          CatBoostClassifier(depth= 5, iterations = 35, learning_rate = 0.35),\n",
    "          ExtraTreesClassifier(n_estimators=200, max_depth=5, random_state=42),\n",
    "          KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
    "          DecisionTreeClassifier(max_depth=7),\n",
    "          SVC(C=1.0, kernel='rbf'),\n",
    "          GaussianNB()]\n",
    "\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  \n",
    "  model.fit(X_train_balanced, Y_train_balanced)\n",
    "  pred = model.predict(X_test)\n",
    " \n",
    "  Accuracy = accuracy_score(Y_test, pred)\n",
    "  mcc = matthews_corrcoef(Y_test, pred)\n",
    "  cm1 = confusion_matrix(Y_test, pred)\n",
    "  kappa = cohen_kappa_score(Y_test, pred)\n",
    "  f1 = f1_score(Y_test, pred)\n",
    "  precision_score = precision_score(Y_test, pred)\n",
    "  recall_score = recall_score(Y_test, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  \n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)\n",
    "total_Metics.to_csv(\"Merge ML_test_adasyn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce26eea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier(max_depth=5, n_estimato...</td>\n",
       "      <td>0.821106</td>\n",
       "      <td>0.604587</td>\n",
       "      <td>0.602950</td>\n",
       "      <td>0.775986</td>\n",
       "      <td>0.704256</td>\n",
       "      <td>0.738383</td>\n",
       "      <td>0.886398</td>\n",
       "      <td>0.704256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.997571</td>\n",
       "      <td>0.994728</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.996618</td>\n",
       "      <td>0.996971</td>\n",
       "      <td>0.998645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LGBMClassifier(max_depth=5, num_leaves=63, ran...</td>\n",
       "      <td>0.992809</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>0.984422</td>\n",
       "      <td>0.982129</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.990051</td>\n",
       "      <td>0.989852</td>\n",
       "      <td>0.998102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GradientBoostingClassifier(learning_rate=0.5, ...</td>\n",
       "      <td>0.996113</td>\n",
       "      <td>0.991584</td>\n",
       "      <td>0.991564</td>\n",
       "      <td>0.990589</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>0.994699</td>\n",
       "      <td>0.998645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.1, n_estima...</td>\n",
       "      <td>0.858906</td>\n",
       "      <td>0.713902</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.753112</td>\n",
       "      <td>0.902142</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.834747</td>\n",
       "      <td>0.902142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.962015</td>\n",
       "      <td>0.961786</td>\n",
       "      <td>0.962299</td>\n",
       "      <td>0.989428</td>\n",
       "      <td>0.975675</td>\n",
       "      <td>0.978340</td>\n",
       "      <td>0.989428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier(max_depth=5, n_estimators...</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.506377</td>\n",
       "      <td>0.505928</td>\n",
       "      <td>0.697308</td>\n",
       "      <td>0.660070</td>\n",
       "      <td>0.678179</td>\n",
       "      <td>0.839897</td>\n",
       "      <td>0.660070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>KNeighborsClassifier(weights='distance')</td>\n",
       "      <td>0.690895</td>\n",
       "      <td>0.522171</td>\n",
       "      <td>0.433820</td>\n",
       "      <td>0.537265</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.697192</td>\n",
       "      <td>0.522266</td>\n",
       "      <td>0.992681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=7)</td>\n",
       "      <td>0.880381</td>\n",
       "      <td>0.757799</td>\n",
       "      <td>0.750273</td>\n",
       "      <td>0.780466</td>\n",
       "      <td>0.927081</td>\n",
       "      <td>0.847479</td>\n",
       "      <td>0.854287</td>\n",
       "      <td>0.927081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.802449</td>\n",
       "      <td>0.588533</td>\n",
       "      <td>0.584569</td>\n",
       "      <td>0.694549</td>\n",
       "      <td>0.801301</td>\n",
       "      <td>0.744116</td>\n",
       "      <td>0.803090</td>\n",
       "      <td>0.801301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.784472</td>\n",
       "      <td>0.542569</td>\n",
       "      <td>0.541112</td>\n",
       "      <td>0.681919</td>\n",
       "      <td>0.747357</td>\n",
       "      <td>0.713140</td>\n",
       "      <td>0.805211</td>\n",
       "      <td>0.747357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                         Classifier  Accuracy  \\\n",
       "0            0  RandomForestClassifier(max_depth=5, n_estimato...  0.821106   \n",
       "1            1  XGBClassifier(base_score=None, booster=None, c...  0.997571   \n",
       "2            2  LGBMClassifier(max_depth=5, num_leaves=63, ran...  0.992809   \n",
       "3            3  GradientBoostingClassifier(learning_rate=0.5, ...  0.996113   \n",
       "4            4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.858906   \n",
       "5            5  <catboost.core.CatBoostClassifier object at 0x...  0.982315   \n",
       "6            6  ExtraTreesClassifier(max_depth=5, n_estimators...  0.775435   \n",
       "7            7           KNeighborsClassifier(weights='distance')  0.690895   \n",
       "8            8                DecisionTreeClassifier(max_depth=7)  0.880381   \n",
       "9            9                                              SVC()  0.802449   \n",
       "10          10                                       GaussianNB()  0.784472   \n",
       "\n",
       "         mcc     Kappa  precision    recall        f1  sensitivity  \\\n",
       "0   0.604587  0.602950   0.775986  0.704256  0.738383     0.886398   \n",
       "1   0.994728  0.994723   0.994600  0.998645  0.996618     0.996971   \n",
       "2   0.984500  0.984422   0.982129  0.998102  0.990051     0.989852   \n",
       "3   0.991584  0.991564   0.990589  0.998645  0.994600     0.994699   \n",
       "4   0.713902  0.706064   0.753112  0.902142  0.820918     0.834747   \n",
       "5   0.962015  0.961786   0.962299  0.989428  0.975675     0.978340   \n",
       "6   0.506377  0.505928   0.697308  0.660070  0.678179     0.839897   \n",
       "7   0.522171  0.433820   0.537265  0.992681  0.697192     0.522266   \n",
       "8   0.757799  0.750273   0.780466  0.927081  0.847479     0.854287   \n",
       "9   0.588533  0.584569   0.694549  0.801301  0.744116     0.803090   \n",
       "10  0.542569  0.541112   0.681919  0.747357  0.713140     0.805211   \n",
       "\n",
       "    specificity  \n",
       "0      0.704256  \n",
       "1      0.998645  \n",
       "2      0.998102  \n",
       "3      0.998645  \n",
       "4      0.902142  \n",
       "5      0.989428  \n",
       "6      0.660070  \n",
       "7      0.992681  \n",
       "8      0.927081  \n",
       "9      0.801301  \n",
       "10     0.747357  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Result = pd.read_csv('Merge ML_test_adasyn.csv')\n",
    "Test_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad31582",
   "metadata": {},
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc66f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d548d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPool1D, Flatten\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef,precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score \n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Merge Copy.csv')\n",
    "\n",
    "\n",
    "# Store the variable we are predicting\n",
    "target = 'target'\n",
    "Y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12066847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before ADASYN: Counter({0: 15545, 1: 8467})\n",
      "The number of classes after ADASYN: Counter({0: 15545, 1: 14878})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "adasyn = ADASYN()\n",
    "\n",
    "# Resample the training data\n",
    "xtrain_balanced, ytrain_balanced = adasyn.fit_resample(xtrain, ytrain)\n",
    "\n",
    "# Print the number of classes before and after resampling\n",
    "print(\"The number of classes before ADASYN: {}\".format(Counter(ytrain)))\n",
    "print(\"The number of classes after ADASYN: {}\".format(Counter(ytrain_balanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28b2e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 195ms/step - accuracy: 0.6910 - loss: 0.5903\n",
      "Epoch 2/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 202ms/step - accuracy: 0.9626 - loss: 0.1084\n",
      "Epoch 3/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 205ms/step - accuracy: 0.9941 - loss: 0.0204\n",
      "Epoch 4/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 210ms/step - accuracy: 0.9979 - loss: 0.0065\n",
      "Epoch 5/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 209ms/step - accuracy: 0.9999 - loss: 0.0017\n",
      "Epoch 6/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 1.7891e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 4.7155e-05\n",
      "Epoch 8/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.8701e-05\n",
      "Epoch 9/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 2.2182e-05\n",
      "Epoch 10/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 1.5963e-05\n",
      "Epoch 11/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 1.1916e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 9.2848e-06\n",
      "Epoch 13/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 7.8296e-06\n",
      "Epoch 14/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 5.9440e-06\n",
      "Epoch 15/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 4.5620e-06\n",
      "Epoch 16/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 3.6445e-06\n",
      "Epoch 17/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 2.9420e-06\n",
      "Epoch 18/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 2.2887e-06\n",
      "Epoch 19/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.8091e-06\n",
      "Epoch 20/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.4799e-06\n",
      "Epoch 21/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1559e-06\n",
      "Epoch 22/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 9.3577e-07\n",
      "Epoch 23/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 7.5735e-07\n",
      "Epoch 24/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 6.3535e-07\n",
      "Epoch 25/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 5.1627e-07\n",
      "Epoch 26/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 4.0744e-07\n",
      "Epoch 27/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 3.3270e-07\n",
      "Epoch 28/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 2.4859e-07\n",
      "Epoch 29/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 2.3092e-07\n",
      "Epoch 30/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 1.7288e-07\n",
      "Epoch 31/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 1.5037e-07\n",
      "Epoch 32/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 1.1276e-07\n",
      "Epoch 33/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 9.0174e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 7.4672e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 6.0739e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 5.0083e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 3.7858e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 3.0094e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 2.6862e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 2.2347e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2101df84610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training data to numpy arrays and reshape for Conv1D input\n",
    "xtrain_balanced = xtrain_balanced.to_numpy().reshape(xtrain_balanced.shape[0], xtrain_balanced.shape[1], 1)\n",
    "ytrain_balanced = ytrain_balanced.to_numpy()\n",
    "\n",
    "# Define KFold for cross-validation\n",
    "kf = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Iterate over KFold splits\n",
    "for train_index, val_index in kf.split(xtrain_balanced):\n",
    "    X_train, X_val = xtrain_balanced[train_index], xtrain_balanced[val_index]\n",
    "    y_train, y_val = ytrain_balanced[train_index], ytrain_balanced[val_index]\n",
    "\n",
    "# Build the CNN model\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(MaxPool1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.fit(X_train, y_train, epochs = 40, batch_size= 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6fd06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m191/191\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step\n"
     ]
    }
   ],
   "source": [
    "  # Predict on the validation set\n",
    "pred = cnn.predict(X_val)\n",
    "y_pred_classes = np.round(pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4cd8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994904667981591\n",
      "Matthews Correlation Coefficient MCC: 0.9898312447008419\n",
      "Kappa: 0.9898076507792605\n",
      "Precision: 0.9913678618857902\n",
      "F1 Score: 0.9948359153756455\n",
      "Specificity: 0.9915939217588102\n",
      "Sensitivity: 0.9983283182881979\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_classes)\n",
    "mcc = matthews_corrcoef(y_val, y_pred_classes)\n",
    "kappa = cohen_kappa_score(y_val, y_pred_classes)\n",
    "precision = precision_score(y_val, y_pred_classes)\n",
    "f1 = f1_score(y_val, y_pred_classes)\n",
    "    # Calculate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "    \n",
    "    # Print performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Matthews Correlation Coefficient MCC:\", mcc)\n",
    "print(\"Kappa:\", kappa)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55533feb",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40f5efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "sample_size = xtrain.shape[0] # number of samples in train set\n",
    "time_steps  = xtrain.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "\n",
    "train_data_reshaped = xtrain.values.reshape(sample_size,time_steps,input_dimension)\n",
    "n_timesteps = train_data_reshaped.shape[1]\n",
    "n_features  = train_data_reshaped.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb11db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 200ms/step - accuracy: 0.6943 - loss: 0.5778\n",
      "Epoch 2/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 211ms/step - accuracy: 0.9486 - loss: 0.1378\n",
      "Epoch 3/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 230ms/step - accuracy: 0.9917 - loss: 0.0264\n",
      "Epoch 4/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 211ms/step - accuracy: 0.9974 - loss: 0.0094\n",
      "Epoch 5/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 202ms/step - accuracy: 0.9960 - loss: 0.0113\n",
      "Epoch 6/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 202ms/step - accuracy: 0.9980 - loss: 0.0072\n",
      "Epoch 7/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 201ms/step - accuracy: 0.9968 - loss: 0.0085\n",
      "Epoch 8/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 203ms/step - accuracy: 0.9999 - loss: 0.0012\n",
      "Epoch 9/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 202ms/step - accuracy: 0.9954 - loss: 0.0126\n",
      "Epoch 10/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 203ms/step - accuracy: 0.9998 - loss: 7.4579e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 0.9963 - loss: 0.0101\n",
      "Epoch 12/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 0.9981 - loss: 0.0059\n",
      "Epoch 13/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 0.9991 - loss: 0.0026\n",
      "Epoch 14/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 0.9978 - loss: 0.0077\n",
      "Epoch 15/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 0.9992 - loss: 0.0024\n",
      "Epoch 16/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 5.0703e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.0975e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 6.4755e-06\n",
      "Epoch 19/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 5.1622e-06\n",
      "Epoch 20/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.0697e-06\n",
      "Epoch 21/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 3.4052e-06\n",
      "Epoch 22/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.5446e-06\n",
      "Epoch 23/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.8939e-06\n",
      "Epoch 24/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 1.5497e-06\n",
      "Epoch 25/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.2260e-06\n",
      "Epoch 26/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.0745e-06\n",
      "Epoch 27/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 8.7341e-07\n",
      "Epoch 28/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 7.5673e-07\n",
      "Epoch 29/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 6.1320e-07\n",
      "Epoch 30/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.9067e-07\n",
      "Epoch 31/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 4.2351e-07\n",
      "Epoch 32/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 3.3866e-07\n",
      "Epoch 33/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 3.0554e-07\n",
      "Epoch 34/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 2.2420e-07\n",
      "Epoch 35/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 1.8112e-07\n",
      "Epoch 36/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 1.7074e-07\n",
      "Epoch 37/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 1.3382e-07\n",
      "Epoch 38/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 1.1228e-07\n",
      "Epoch 39/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 417ms/step - accuracy: 1.0000 - loss: 8.7552e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m381/381\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 6.2038e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2103d923590>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(MaxPool1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.fit(X_train, y_train, epochs = 40, batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26132c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 77ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = cnn.predict(xtest)\n",
    "pred = (pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "413a8eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9976678651248664\n",
      "Matthews Correlation Coefficient MCC: 0.9949061808443106\n",
      "Kappa: 0.9949053738751028\n",
      "Precision: 0.9958937859293732\n",
      "F1 Score: 0.9967123287671232\n",
      "Specificity: 0.9977423239012643\n",
      "Sensitivity: 0.9975322182615849\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest, pred)\n",
    "mcc = matthews_corrcoef(ytest, pred)\n",
    "kappa = cohen_kappa_score(ytest, pred)\n",
    "precision = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "    \n",
    "cm = confusion_matrix(ytest, pred)\n",
    "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "    \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Matthews Correlation Coefficient MCC:\", mcc)\n",
    "print(\"Kappa:\", kappa)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e6b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f018203",
   "metadata": {},
   "source": [
    "# **Deep_TPPred**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae066d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPool1D, Flatten\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef,precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score \n",
    "\n",
    "from keras.layers import SimpleRNN, Reshape\n",
    "\n",
    "df = pd.read_csv('Merge Copy.csv')\n",
    "\n",
    "# Store the variable we are predicting\n",
    "target = 'target'\n",
    "Y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7454435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before ADASYN: Counter({0: 15498, 1: 8514})\n",
      "The number of classes after ADASYN: Counter({0: 15498, 1: 14884})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "adasyn = ADASYN()\n",
    "# Resample the training data\n",
    "xtrain_balanced, ytrain_balanced = adasyn.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"The number of classes before ADASYN: {}\".format(Counter(ytrain)))\n",
    "print(\"The number of classes after ADASYN: {}\".format(Counter(ytrain_balanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ff2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to numpy arrays\n",
    "xtrain_balanced = xtrain_balanced.to_numpy()\n",
    "ytrain_balanced = ytrain_balanced.to_numpy()\n",
    "\n",
    "# Define KFold for cross-validation\n",
    "kf = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Iterate over KFold splits\n",
    "for train_index, val_index in kf.split(xtrain_balanced):\n",
    "    X_train, X_val = xtrain_balanced[train_index], xtrain_balanced[val_index]\n",
    "    y_train, y_val = ytrain_balanced[train_index], ytrain_balanced[val_index]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcb2c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 217ms/step - accuracy: 0.6686 - loss: 0.5972\n",
      "Epoch 2/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 219ms/step - accuracy: 0.9145 - loss: 0.2096\n",
      "Epoch 3/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 251ms/step - accuracy: 0.9898 - loss: 0.0333\n",
      "Epoch 4/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 260ms/step - accuracy: 0.9956 - loss: 0.0111\n",
      "Epoch 5/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 234ms/step - accuracy: 0.9979 - loss: 0.0065\n",
      "Epoch 6/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 240ms/step - accuracy: 0.9991 - loss: 0.0035\n",
      "Epoch 7/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 245ms/step - accuracy: 0.9959 - loss: 0.0159\n",
      "Epoch 8/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 250ms/step - accuracy: 0.9987 - loss: 0.0037\n",
      "Epoch 9/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 227ms/step - accuracy: 0.9981 - loss: 0.0051\n",
      "Epoch 10/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 229ms/step - accuracy: 0.9997 - loss: 8.9935e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 251ms/step - accuracy: 0.9968 - loss: 0.0100\n",
      "Epoch 12/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 253ms/step - accuracy: 0.9991 - loss: 0.0026\n",
      "Epoch 13/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 2.0808e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 9.1599e-06\n",
      "Epoch 15/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 6.2638e-06\n",
      "Epoch 16/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 4.2395e-06\n",
      "Epoch 17/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 3.0586e-06\n",
      "Epoch 18/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 2.9960e-06\n",
      "Epoch 19/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 1.8944e-06\n",
      "Epoch 20/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 1.4820e-06\n",
      "Epoch 21/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1976e-06\n",
      "Epoch 22/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 9.2774e-07\n",
      "Epoch 23/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 8.0807e-07\n",
      "Epoch 24/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 5.6886e-07\n",
      "Epoch 25/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 5.1740e-07\n",
      "Epoch 26/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 281ms/step - accuracy: 1.0000 - loss: 3.7604e-07\n",
      "Epoch 27/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 3.1548e-07\n",
      "Epoch 28/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 2.5311e-07\n",
      "Epoch 29/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 2.1926e-07\n",
      "Epoch 30/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 1.5225e-07\n",
      "Epoch 31/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 1.3342e-07\n",
      "Epoch 32/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.0008e-07\n",
      "Epoch 33/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 8.5937e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 6.6614e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 5.7285e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 4.5529e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 3.2578e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 2.4724e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 2.0983e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.9066e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28045feda10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(MaxPool1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add Simple RNN layer\n",
    "cnn.add(Reshape((-1, 64)))  # Flatten the output before passing to RNN\n",
    "cnn.add(SimpleRNN(64, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile and train the model\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(X_train, y_train, epochs=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5ae87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "  # Predict on the validation set\n",
    "pred = cnn.predict(X_val)\n",
    "y_pred_classes = np.round(pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b601e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9960500329163924\n",
      "Matthews Correlation Coefficient MCC: 0.9920985026055685\n",
      "Kappa: 0.9920965660190711\n",
      "Precision: 0.994961370507222\n",
      "F1 Score: 0.9959650302622729\n",
      "Specificity: 0.9951690821256038\n",
      "Sensitivity: 0.9969707169303265\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, y_pred_classes)\n",
    "mcc = matthews_corrcoef(y_val, y_pred_classes)\n",
    "kappa = cohen_kappa_score(y_val, y_pred_classes)\n",
    "precision = precision_score(y_val, y_pred_classes)\n",
    "f1 = f1_score(y_val, y_pred_classes)\n",
    "    # Calculate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "    \n",
    "    # Print performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Matthews Correlation Coefficient MCC:\", mcc)\n",
    "print(\"Kappa:\", kappa)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f5b64-ebc7-4e43-bd8f-d30c5b228459",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ebcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sample_size = xtrain.shape[0] # number of samples in train set\n",
    "time_steps  = xtrain.shape[1] # number of features in train set\n",
    "input_dimension = 1               # each feature is represented by 1 number\n",
    "\n",
    "\n",
    "train_data_reshaped = xtrain.values.reshape(sample_size,time_steps,input_dimension)\n",
    "n_timesteps = train_data_reshaped.shape[1]\n",
    "n_features  = train_data_reshaped.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a224b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 194ms/step - accuracy: 0.6735 - loss: 0.6093\n",
      "Epoch 2/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 197ms/step - accuracy: 0.9323 - loss: 0.1745\n",
      "Epoch 3/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 0.9918 - loss: 0.0268\n",
      "Epoch 4/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 0.9960 - loss: 0.0115\n",
      "Epoch 5/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 0.9965 - loss: 0.0109\n",
      "Epoch 6/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 0.9980 - loss: 0.0064\n",
      "Epoch 7/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 0.9950 - loss: 0.0180\n",
      "Epoch 8/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 0.9964 - loss: 0.0101\n",
      "Epoch 9/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 0.9993 - loss: 0.0019\n",
      "Epoch 10/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.4745e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 2.3663e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 8.8933e-06\n",
      "Epoch 13/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 5.5966e-06\n",
      "Epoch 14/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.1173e-06\n",
      "Epoch 15/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 3.6257e-06\n",
      "Epoch 16/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.7224e-06\n",
      "Epoch 17/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.8984e-06\n",
      "Epoch 18/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.9117e-06\n",
      "Epoch 19/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 1.1253e-06\n",
      "Epoch 20/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.0426e-06\n",
      "Epoch 21/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 8.5593e-07\n",
      "Epoch 22/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 6.6821e-07\n",
      "Epoch 23/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 4.9956e-07\n",
      "Epoch 24/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 3.9357e-07\n",
      "Epoch 25/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 3.3974e-07\n",
      "Epoch 26/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 2.8386e-07\n",
      "Epoch 27/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 2.2582e-07\n",
      "Epoch 28/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.9104e-07\n",
      "Epoch 29/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 1.4530e-07\n",
      "Epoch 30/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.2766e-07\n",
      "Epoch 31/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.0404e-07\n",
      "Epoch 32/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 8.5344e-08\n",
      "Epoch 33/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 7.8102e-08\n",
      "Epoch 34/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 5.6159e-08\n",
      "Epoch 35/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.7476e-08\n",
      "Epoch 36/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 4.0800e-08\n",
      "Epoch 37/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 3.1496e-08\n",
      "Epoch 38/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 2.5288e-08\n",
      "Epoch 39/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.0237e-08\n",
      "Epoch 40/40\n",
      "\u001b[1m380/380\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.5932e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28028270310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "cnn.add(MaxPool1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add Simple RNN layer\n",
    "cnn.add(Reshape((-1, 64)))  # Flatten the output before passing to RNN\n",
    "cnn.add(SimpleRNN(64, activation='relu'))\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile and train the model\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(X_train, y_train, epochs=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0cc16fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m322/322\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = cnn.predict(xtest)\n",
    "pred = (pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f828871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9983480711301137\n",
      "Matthews Correlation Coefficient MCC: 0.9963748011826989\n",
      "Kappa: 0.996374778527703\n",
      "Precision: 0.9977857735953501\n",
      "F1 Score: 0.9976477099764771\n",
      "Specificity: 0.9988018571214617\n",
      "Sensitivity: 0.9975096845600443\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest, pred)\n",
    "mcc = matthews_corrcoef(ytest, pred)\n",
    "kappa = cohen_kappa_score(ytest, pred)\n",
    "precision = precision_score(ytest, pred)\n",
    "f1 = f1_score(ytest, pred)\n",
    "    \n",
    "cm = confusion_matrix(ytest, pred)\n",
    "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "    \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Matthews Correlation Coefficient MCC:\", mcc)\n",
    "print(\"Kappa:\", kappa)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57f74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
